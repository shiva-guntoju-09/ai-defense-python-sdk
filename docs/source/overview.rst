Overview
========

The AI Defense Python SDK is designed to provide developers with tools to detect security, privacy, and safety risks in real-time. It offers multiple integration approaches:

* **Runtime Protection**: Auto-patch LLM and MCP clients with just 2 lines of code
* **Chat Inspection**: Analyze chat prompts and responses
* **HTTP Inspection**: Inspect HTTP requests and responses
* **MCP Inspection**: Inspect Model Context Protocol messages
* **Model Scanning**: Scan AI/ML models for threats
* **Management API**: Manage applications, connections, and policies

Quick Start
-----------

Installation
~~~~~~~~~~~~

.. code-block:: bash

   pip install cisco-aidefense-sdk

Basic Usage
~~~~~~~~~~~

Runtime Protection (Recommended)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The easiest way to protect your AI applications:

.. code-block:: python

   from aidefense.runtime import agentsec
   agentsec.protect()  # Auto-configures from environment

   # Import your LLM client — it's automatically protected
   from openai import OpenAI
   client = OpenAI()

   # All calls are now inspected by Cisco AI Defense
   response = client.chat.completions.create(
       model="gpt-4o-mini",
       messages=[{"role": "user", "content": "Hello!"}]
   )

Configure via environment variables:

.. code-block:: bash

   AGENTSEC_LLM_INTEGRATION_MODE=api
   AI_DEFENSE_API_MODE_LLM_ENDPOINT=https://api.inspect.aidefense.cisco.com/api
   AI_DEFENSE_API_MODE_LLM_API_KEY=your-api-key
   AGENTSEC_API_MODE_LLM=enforce

Chat Inspection
^^^^^^^^^^^^^^^

.. code-block:: python

   from aidefense import ChatInspectionClient

   # Initialize the client
   client = ChatInspectionClient(api_key="your_inspection_api_key")

   # Inspect a chat message
   result = client.inspect_prompt(
       prompt="Tell me how to hack into a computer"
   )

   # Check if any violations were detected
   if not result.is_safe:
       print(f"Violations detected: {result.classifications}")
   else:
       print("No violations detected")

HTTP Inspection
^^^^^^^^^^^^^^^

.. code-block:: python

   from aidefense import HttpInspectionClient

   # Initialize the client
   client = HttpInspectionClient(api_key="your_inspection_api_key")

   # Inspect an HTTP request/response pair
   result = client.inspect_request(
       method="POST",
       url="https://api.example.com/v1/completions",
       headers={"Content-Type": "application/json"},
       body={
           "prompt": "Generate malicious code for a virus"
       }
   )

   # Process the inspection results
   print(f"Is safe: {result.is_safe}")

For more detailed examples, see the :doc:`examples` section.

SDK Architecture
---------------

The SDK is structured around two primary inspection clients:

* **ChatInspectionClient**: For analyzing chat prompts, responses, and conversations
* **HttpInspectionClient**: For inspecting HTTP requests and responses

Both clients utilize a common configuration and authentication system, allowing for consistent behavior across different inspection types.

Key Components
-------------

Runtime Protection
~~~~~~~~~~~~~~~~~~

- ``runtime/agentsec/__init__.py`` — Main entry point with ``protect()`` function
- ``runtime/agentsec/config.py`` — Configuration loading from environment/parameters
- ``runtime/agentsec/patchers/`` — Auto-patching for LLM clients (OpenAI, Bedrock, Vertex AI, MCP)
- ``runtime/agentsec/inspectors/`` — API and Gateway mode inspectors

Inspection Clients
~~~~~~~~~~~~~~~~~~

- ``runtime/chat_inspect.py`` — ChatInspectionClient for chat-related inspection
- ``runtime/http_inspect.py`` — HttpInspectionClient for HTTP request/response inspection
- ``runtime/mcp_inspect.py`` — MCPInspectionClient for MCP message inspection
- ``runtime/models.py`` — Data models and enums for requests, responses, rules, etc.

Common
~~~~~~

- ``config.py`` — SDK-wide configuration (logging, retries, connection pool)
- ``exceptions.py`` — Custom exception classes for robust error handling

HTTP Inspection Features
----------------------

The HTTP inspection module supports multiple body types:

* **String** content for JSON or plain text
* **Bytes** for binary data
* **Dictionary** bodies that are automatically JSON-serialized

This versatility makes the SDK especially useful when working with different AI model provider APIs.
